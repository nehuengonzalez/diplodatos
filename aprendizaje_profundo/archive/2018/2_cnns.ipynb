{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0b02df97-cbb3-4759-9371-cbbecd0ccd86"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Construyendo una red convolucional con Keras\n",
    "\n",
    "El código de esta notebook, exceptuando el modelo en sí, es muy similar a la notebook 1 vista en la última clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "fa44eec5-93b3-4e4b-adcb-1065bb5cc474"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras import optimizers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "79849185-892a-41ce-b4a2-26db6ad19597"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cargando los datos del MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128  # For mini-batch gradient descent\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "input_size = 28*28\n",
    "train_examples = 60000\n",
    "test_examples = 10000\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape the dataset to convert the examples from 2D matrixes to 1D arrays.\n",
    "x_train = x_train.reshape(train_examples, input_size)\n",
    "x_test = x_test.reshape(test_examples, input_size)\n",
    "\n",
    "# normalize the input\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos redimensionar el input para obtener la imagen en 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28  # sqrt(784)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construímos nuestro modelo agregando una [capa convolucional](https://keras.io/layers/convolutional/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué tamaño tiene la salida de la primera convolución?\n",
    "\n",
    "(???, ???, ???, ???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.3459 - acc: 0.8967 - val_loss: 0.0933 - val_acc: 0.9725\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.1404 - acc: 0.9588 - val_loss: 0.0665 - val_acc: 0.9794\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.1072 - acc: 0.9681 - val_loss: 0.0555 - val_acc: 0.9812\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0911 - acc: 0.9725 - val_loss: 0.0488 - val_acc: 0.9826\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0795 - acc: 0.9769 - val_loss: 0.0467 - val_acc: 0.9835\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0719 - acc: 0.9789 - val_loss: 0.0430 - val_acc: 0.9841\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0645 - acc: 0.9809 - val_loss: 0.0387 - val_acc: 0.9863\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0596 - acc: 0.9817 - val_loss: 0.0407 - val_acc: 0.9851\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0551 - acc: 0.9827 - val_loss: 0.0383 - val_acc: 0.9860\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0543 - acc: 0.9836 - val_loss: 0.0372 - val_acc: 0.9868\n",
      "Test loss: 0.03721193906484987\n",
      "Test accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:diplodatos]",
   "language": "python",
   "name": "conda-env-diplodatos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
